Sender: LSF System <lsfadmin@polus-c1-ib.bmc.hpc.cs.msu.ru>
Subject: Job 872376: <module load OpenMPI/2.1.3;module load Anaconda3/2019.07;source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh;conda activate;#BSUB -n 40 -q normal;#BSUB -W 03:00;#BSUB  -o result.out;#BSUB  -e result.err; mpiexec -n 1 python main.py;mpiexec -n 2 python main.py;mpiexec -n 4 python main.py;mpiexec -n 8 python main.py;mpiexec -n 16 python main.py;mpiexec -n 32 python main.py> in cluster <MSUCluster> Exited

Job <module load OpenMPI/2.1.3;module load Anaconda3/2019.07;source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh;conda activate;#BSUB -n 40 -q normal;#BSUB -W 03:00;#BSUB  -o result.out;#BSUB  -e result.err; mpiexec -n 1 python main.py;mpiexec -n 2 python main.py;mpiexec -n 4 python main.py;mpiexec -n 8 python main.py;mpiexec -n 16 python main.py;mpiexec -n 32 python main.py> was submitted from host <polus-ib.bmc.hpc.cs.msu.ru> by user <edu-cmc-sqi21-19> in cluster <MSUCluster> at Thu Mar 10 13:08:25 2022
Job was executed on host(s) <20*polus-c1-ib.bmc.hpc.cs.msu.ru>, in queue <normal>, as user <edu-cmc-sqi21-19> in cluster <MSUCluster> at Thu Mar 10 13:08:26 2022
                            <20*polus-c4-ib.bmc.hpc.cs.msu.ru>
</home_edu/edu-cmc-sqi21/edu-cmc-sqi21-19> was used as the home directory.
</home_edu/edu-cmc-sqi21/edu-cmc-sqi21-19/HD> was used as the working directory.
Started at Thu Mar 10 13:08:26 2022
Terminated at Thu Mar 10 16:08:26 2022
Results reported at Thu Mar 10 16:08:26 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
module load OpenMPI/2.1.3
module load Anaconda3/2019.07
source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh
conda activate
#BSUB -n 40 -q normal
#BSUB -W 03:00
#BSUB  -o result.out
#BSUB  -e result.err

mpiexec -n 1 python main.py
mpiexec -n 2 python main.py
mpiexec -n 4 python main.py
mpiexec -n 8 python main.py
mpiexec -n 16 python main.py
mpiexec -n 32 python main.py


------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   17720.00 sec.
    Max Memory :                                 512 MB
    Average Memory :                             237.89 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   2 MB
    Max Processes :                              9
    Max Threads :                                333
    Run time :                                   10804 sec.
    Turnaround time :                            10801 sec.

The output (if any) follows:

==================================
          WORLD SIZE: 1          
==================================
Picked model: Human. Total model count: 11
GoldenRetriever.stl found and loaded!
Wolf.stl found and loaded!
Horse.stl found and loaded!
Lion.stl found and loaded!
Eagle.stl found and loaded!
Dolphin.stl found and loaded!
Bull.stl found and loaded!
Dog.stl found and loaded!
Camel.stl found and loaded!
Giraffe.stl found and loaded!
Human.stl found and loaded!
---------------------   PARALLEL   ---------------------
MPI M11 <-> M1: 15.432489
MPI M11 <-> M2: 18.513230
MPI M11 <-> M3: 4.436152
MPI M11 <-> M4: 30.473041
MPI M11 <-> M5: 19.901475
MPI M11 <-> M6: 5.794676
MPI M11 <-> M7: 10.982179
MPI M11 <-> M8: 12.330344
MPI M11 <-> M9: 16.919686
MPI M11 <-> M10: 19.180605
Parallel Elapsed Time: 6344.30383 seconds.
---------------------------------------------------

==================================
          WORLD SIZE: 2          
==================================
Picked model: Human. Total model count: 11
GoldenRetriever.stl found and loaded!
Wolf.stl found and loaded!
Horse.stl found and loaded!
Lion.stl found and loaded!
Eagle.stl found and loaded!
Dolphin.stl found and loaded!
Bull.stl found and loaded!
Dog.stl found and loaded!
Camel.stl found and loaded!
Giraffe.stl found and loaded!
Human.stl found and loaded!
---------------------   PARALLEL   ---------------------
MPI M11 <-> M1: 15.432489
MPI M11 <-> M2: 18.513230
MPI M11 <-> M3: 4.436152
MPI M11 <-> M4: 30.473041
MPI M11 <-> M5: 19.901475
MPI M11 <-> M6: 5.794676
MPI M11 <-> M7: 10.982179
MPI M11 <-> M8: 12.330344
MPI M11 <-> M9: 16.919686
MPI M11 <-> M10: 19.180605
Parallel Elapsed Time: 3211.60426 seconds.
---------------------------------------------------

==================================
          WORLD SIZE: 4          
==================================
Picked model: Human. Total model count: 11
GoldenRetriever.stl found and loaded!
Wolf.stl found and loaded!
Horse.stl found and loaded!
Lion.stl found and loaded!
Eagle.stl found and loaded!
Dolphin.stl found and loaded!
Bull.stl found and loaded!
Dog.stl found and loaded!
Camel.stl found and loaded!
Giraffe.stl found and loaded!
Human.stl found and loaded!
---------------------   PARALLEL   ---------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 0 on node polus-c1-ib exited on signal 12 (User defined signal 2).
--------------------------------------------------------------------------


PS:

Read file <result.err> for stderr output of this job.

Sender: LSF System <lsfadmin@polus-c4-ib.bmc.hpc.cs.msu.ru>
Subject: Job 872382: <module load OpenMPI/2.1.3;module load Anaconda3/2019.07;source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh;conda activate;#BSUB -n 32 -q normal;#BSUB -W 03:00;#BSUB  -o result.out;#BSUB  -e result.err; #mpiexec -n 1 python main.py;#mpiexec -n 2 python main.py;mpiexec -n 4 python main.py;mpiexec -n 8 python main.py;mpiexec -n 16 python main.py;#mpiexec -n 32 python main.py;#mpiexec -n 64 python main.py> in cluster <MSUCluster> Done

Job <module load OpenMPI/2.1.3;module load Anaconda3/2019.07;source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh;conda activate;#BSUB -n 32 -q normal;#BSUB -W 03:00;#BSUB  -o result.out;#BSUB  -e result.err; #mpiexec -n 1 python main.py;#mpiexec -n 2 python main.py;mpiexec -n 4 python main.py;mpiexec -n 8 python main.py;mpiexec -n 16 python main.py;#mpiexec -n 32 python main.py;#mpiexec -n 64 python main.py> was submitted from host <polus-ib.bmc.hpc.cs.msu.ru> by user <edu-cmc-sqi21-19> in cluster <MSUCluster> at Fri Mar 11 11:39:03 2022
Job was executed on host(s) <20*polus-c4-ib.bmc.hpc.cs.msu.ru>, in queue <normal>, as user <edu-cmc-sqi21-19> in cluster <MSUCluster> at Fri Mar 11 11:39:03 2022
                            <12*polus-c1-ib.bmc.hpc.cs.msu.ru>
</home_edu/edu-cmc-sqi21/edu-cmc-sqi21-19> was used as the home directory.
</home_edu/edu-cmc-sqi21/edu-cmc-sqi21-19/HD> was used as the working directory.
Started at Fri Mar 11 11:39:03 2022
Terminated at Fri Mar 11 12:25:53 2022
Results reported at Fri Mar 11 12:25:53 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
module load OpenMPI/2.1.3
module load Anaconda3/2019.07
source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh
conda activate
#BSUB -n 32 -q normal
#BSUB -W 03:00
#BSUB  -o result.out
#BSUB  -e result.err

#mpiexec -n 1 python main.py
#mpiexec -n 2 python main.py
mpiexec -n 4 python main.py
mpiexec -n 8 python main.py
mpiexec -n 16 python main.py
#mpiexec -n 32 python main.py
#mpiexec -n 64 python main.py

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   19486.15 sec.
    Max Memory :                                 1906 MB
    Average Memory :                             853.69 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              21
    Max Threads :                                329
    Run time :                                   2813 sec.
    Turnaround time :                            2810 sec.

The output (if any) follows:

==================================
          WORLD SIZE: 4          
==================================
Picked model: Human. Total model count: 11
GoldenRetriever.stl found and loaded!
Wolf.stl found and loaded!
Horse.stl found and loaded!
Lion.stl found and loaded!
Eagle.stl found and loaded!
Dolphin.stl found and loaded!
Bull.stl found and loaded!
Dog.stl found and loaded!
Camel.stl found and loaded!
Giraffe.stl found and loaded!
Human.stl found and loaded!
---------------------   PARALLEL   ---------------------
MPI M11 <-> M1: 15.432489
MPI M11 <-> M2: 18.513230
MPI M11 <-> M3: 4.436152
MPI M11 <-> M4: 30.473041
MPI M11 <-> M5: 19.901475
MPI M11 <-> M6: 5.794676
MPI M11 <-> M7: 10.982179
MPI M11 <-> M8: 12.330344
MPI M11 <-> M9: 16.919686
MPI M11 <-> M10: 19.180605
Parallel Elapsed Time: 1581.87771 seconds.
---------------------------------------------------

==================================
          WORLD SIZE: 8          
==================================
Picked model: Human. Total model count: 11
GoldenRetriever.stl found and loaded!
Wolf.stl found and loaded!
Horse.stl found and loaded!
Lion.stl found and loaded!
Eagle.stl found and loaded!
Dolphin.stl found and loaded!
Bull.stl found and loaded!
Dog.stl found and loaded!
Camel.stl found and loaded!
Giraffe.stl found and loaded!
Human.stl found and loaded!
---------------------   PARALLEL   ---------------------
MPI M11 <-> M1: 15.432489
MPI M11 <-> M2: 18.513230
MPI M11 <-> M3: 4.436152
MPI M11 <-> M4: 30.473041
MPI M11 <-> M5: 19.901475
MPI M11 <-> M6: 5.794676
MPI M11 <-> M7: 10.982179
MPI M11 <-> M8: 12.330344
MPI M11 <-> M9: 16.919686
MPI M11 <-> M10: 19.180605
Parallel Elapsed Time: 804.27999 seconds.
---------------------------------------------------

==================================
          WORLD SIZE: 16          
==================================
Picked model: Human. Total model count: 11
GoldenRetriever.stl found and loaded!
Wolf.stl found and loaded!
Horse.stl found and loaded!
Lion.stl found and loaded!
Eagle.stl found and loaded!
Dolphin.stl found and loaded!
Bull.stl found and loaded!
Dog.stl found and loaded!
Camel.stl found and loaded!
Giraffe.stl found and loaded!
Human.stl found and loaded!
---------------------   PARALLEL   ---------------------
MPI M11 <-> M1: 15.432489
MPI M11 <-> M2: 18.513230
MPI M11 <-> M3: 4.436152
MPI M11 <-> M4: 30.473041
MPI M11 <-> M5: 19.901475
MPI M11 <-> M6: 5.794676
MPI M11 <-> M7: 10.982179
MPI M11 <-> M8: 12.330344
MPI M11 <-> M9: 16.919686
MPI M11 <-> M10: 19.180605
Parallel Elapsed Time: 416.85750 seconds.
---------------------------------------------------



PS:

Read file <result.err> for stderr output of this job.

Sender: LSF System <lsfadmin@polus-c4-ib.bmc.hpc.cs.msu.ru>
Subject: Job 872383: <module load OpenMPI/2.1.3;module load Anaconda3/2019.07;source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh;conda activate;#BSUB -n 32 -q normal;#BSUB -W 03:00;#BSUB  -o result.out;#BSUB  -e result.err; #mpiexec -n 1 python main.py;#mpiexec -n 2 python main.py;#mpiexec -n 4 python main.py;#mpiexec -n 8 python main.py;#mpiexec -n 16 python main.py;mpiexec -n 32 python main.py;#mpiexec -n 64 python main.py> in cluster <MSUCluster> Done

Job <module load OpenMPI/2.1.3;module load Anaconda3/2019.07;source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh;conda activate;#BSUB -n 32 -q normal;#BSUB -W 03:00;#BSUB  -o result.out;#BSUB  -e result.err; #mpiexec -n 1 python main.py;#mpiexec -n 2 python main.py;#mpiexec -n 4 python main.py;#mpiexec -n 8 python main.py;#mpiexec -n 16 python main.py;mpiexec -n 32 python main.py;#mpiexec -n 64 python main.py> was submitted from host <polus-ib.bmc.hpc.cs.msu.ru> by user <edu-cmc-sqi21-19> in cluster <MSUCluster> at Fri Mar 11 12:53:18 2022
Job was executed on host(s) <20*polus-c4-ib.bmc.hpc.cs.msu.ru>, in queue <normal>, as user <edu-cmc-sqi21-19> in cluster <MSUCluster> at Fri Mar 11 12:53:19 2022
                            <12*polus-c1-ib.bmc.hpc.cs.msu.ru>
</home_edu/edu-cmc-sqi21/edu-cmc-sqi21-19> was used as the home directory.
</home_edu/edu-cmc-sqi21/edu-cmc-sqi21-19/HD> was used as the working directory.
Started at Fri Mar 11 12:53:19 2022
Terminated at Fri Mar 11 12:57:11 2022
Results reported at Fri Mar 11 12:57:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
module load OpenMPI/2.1.3
module load Anaconda3/2019.07
source /polusfs/modules/anaconda/anaconda-3/etc/profile.d/conda.sh
conda activate
#BSUB -n 32 -q normal
#BSUB -W 03:00
#BSUB  -o result.out
#BSUB  -e result.err

#mpiexec -n 1 python main.py
#mpiexec -n 2 python main.py
#mpiexec -n 4 python main.py
#mpiexec -n 8 python main.py
#mpiexec -n 16 python main.py
mpiexec -n 32 python main.py
#mpiexec -n 64 python main.py

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7022.78 sec.
    Max Memory :                                 3767 MB
    Average Memory :                             3325.18 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              37
    Max Threads :                                1457
    Run time :                                   232 sec.
    Turnaround time :                            233 sec.

The output (if any) follows:

==================================
          WORLD SIZE: 32          
==================================
Picked model: Human. Total model count: 11
GoldenRetriever.stl found and loaded!
Wolf.stl found and loaded!
Horse.stl found and loaded!
Lion.stl found and loaded!
Eagle.stl found and loaded!
Dolphin.stl found and loaded!
Bull.stl found and loaded!
Dog.stl found and loaded!
Camel.stl found and loaded!
Giraffe.stl found and loaded!
Human.stl found and loaded!
---------------------   PARALLEL   ---------------------
MPI M11 <-> M1: 15.432489
MPI M11 <-> M2: 18.513230
MPI M11 <-> M3: 4.436152
MPI M11 <-> M4: 30.473041
MPI M11 <-> M5: 19.901475
MPI M11 <-> M6: 5.794676
MPI M11 <-> M7: 10.982179
MPI M11 <-> M8: 12.330344
MPI M11 <-> M9: 16.919686
MPI M11 <-> M10: 19.180605
Parallel Elapsed Time: 227.58150 seconds.
---------------------------------------------------



PS:

Read file <result.err> for stderr output of this job.

